{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edaabf6d-afe8-4023-8fbf-dd8007898dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mtcnn import MTCNN\n",
    "from keras_facenet import FaceNet\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2e1c89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mtcnn in c:\\users\\user\\anaconda3\\envs\\py_3.7.4\\lib\\site-packages (0.1.1)\n",
      "Requirement already satisfied: keras>=2.0.0 in c:\\users\\user\\anaconda3\\envs\\py_3.7.4\\lib\\site-packages (from mtcnn) (2.4.3)\n",
      "Requirement already satisfied: opencv-python>=4.1.0 in c:\\users\\user\\anaconda3\\envs\\py_3.7.4\\lib\\site-packages (from mtcnn) (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\user\\anaconda3\\envs\\py_3.7.4\\lib\\site-packages (from keras>=2.0.0->mtcnn) (1.18.5)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\user\\anaconda3\\envs\\py_3.7.4\\lib\\site-packages (from keras>=2.0.0->mtcnn) (6.0.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\user\\anaconda3\\envs\\py_3.7.4\\lib\\site-packages (from keras>=2.0.0->mtcnn) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\user\\anaconda3\\envs\\py_3.7.4\\lib\\site-packages (from keras>=2.0.0->mtcnn) (1.4.1)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\envs\\py_3.7.4\\lib\\site-packages (from h5py->keras>=2.0.0->mtcnn) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7414b9a-9840-4907-b3a4-5285fa4faf44",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.api.backend' has no attribute 'int_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minception_resnet_v1\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#Step 2\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m inception_resnet_v1\u001b[38;5;241m.\u001b[39mInceptionResNetV1()\n\u001b[0;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfacenet_keras_weights.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\Semester 6\\Computer Vision\\facereg-facenet\\inception_resnet_v1.py:126\u001b[0m, in \u001b[0;36mInceptionResNetV1\u001b[1;34m(input_shape, classes, dropout_keep_prob, weights_path)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# 5x Block35 (Inception-ResNet-A block):\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m6\u001b[39m):\n\u001b[1;32m--> 126\u001b[0m     x \u001b[38;5;241m=\u001b[39m _inception_resnet_block(x,\n\u001b[0;32m    127\u001b[0m                                 scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.17\u001b[39m,\n\u001b[0;32m    128\u001b[0m                                 block_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlock35\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    129\u001b[0m                                 block_idx\u001b[38;5;241m=\u001b[39mblock_idx)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m# Mixed 6a (Reduction-A block):\u001b[39;00m\n\u001b[0;32m    132\u001b[0m channel_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m K\u001b[38;5;241m.\u001b[39mimage_data_format() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannels_first\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m3\u001b[39m\n",
      "File \u001b[1;32m~\\Documents\\Semester 6\\Computer Vision\\facereg-facenet\\inception_resnet_v1.py:97\u001b[0m, in \u001b[0;36m_inception_resnet_block\u001b[1;34m(x, scale, block_type, block_idx, activation)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown Inception-ResNet block type. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     92\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpects \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlock35\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlock17\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlock8\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     93\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbut got: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(block_type))\n\u001b[0;32m     95\u001b[0m mixed \u001b[38;5;241m=\u001b[39m Concatenate(axis\u001b[38;5;241m=\u001b[39mchannel_axis, name\u001b[38;5;241m=\u001b[39mname_fmt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConcatenate\u001b[39m\u001b[38;5;124m'\u001b[39m))(branches)\n\u001b[0;32m     96\u001b[0m up \u001b[38;5;241m=\u001b[39m conv2d_bn(mixed,\n\u001b[1;32m---> 97\u001b[0m                K\u001b[38;5;241m.\u001b[39mint_shape(x)[channel_axis],\n\u001b[0;32m     98\u001b[0m                \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     99\u001b[0m                activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    100\u001b[0m                use_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    101\u001b[0m                name\u001b[38;5;241m=\u001b[39mname_fmt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConv2d_1x1\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m    102\u001b[0m up \u001b[38;5;241m=\u001b[39m Lambda(scaling,\n\u001b[0;32m    103\u001b[0m             output_shape\u001b[38;5;241m=\u001b[39mK\u001b[38;5;241m.\u001b[39mint_shape(up)[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    104\u001b[0m             arguments\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m'\u001b[39m: scale})(up)\n\u001b[0;32m    105\u001b[0m x \u001b[38;5;241m=\u001b[39m add([x, up])\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.api.backend' has no attribute 'int_shape'"
     ]
    }
   ],
   "source": [
    "#Step 1\n",
    "import inception_resnet_v1\n",
    "\n",
    "#Step 2\n",
    "model = inception_resnet_v1.InceptionResNetV1()\n",
    "model.load_weights('facenet_keras_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc5155a3-b234-497f-b190-a71fddc7fcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras_facenet\n",
      "  Downloading keras-facenet-0.3.2.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: mtcnn in c:\\users\\user\\anaconda3\\envs\\face_recognition\\lib\\site-packages (from keras_facenet) (1.0.0)\n",
      "Requirement already satisfied: joblib>=1.4.2 in c:\\users\\user\\anaconda3\\envs\\face_recognition\\lib\\site-packages (from mtcnn->keras_facenet) (1.4.2)\n",
      "Requirement already satisfied: lz4>=4.3.3 in c:\\users\\user\\anaconda3\\envs\\face_recognition\\lib\\site-packages (from mtcnn->keras_facenet) (4.4.4)\n",
      "Building wheels for collected packages: keras_facenet\n",
      "  Building wheel for keras_facenet (setup.py): started\n",
      "  Building wheel for keras_facenet (setup.py): finished with status 'done'\n",
      "  Created wheel for keras_facenet: filename=keras_facenet-0.3.2-py3-none-any.whl size=10386 sha256=1f07caa53283eb35ea055fc0c29c21bbc21a12dac3ce6ff30f90284e4e819a46\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\99\\94\\dd\\cb1a65a7440ba6d508bd24346c15af0b1d24ff8b1cdb1c9959\n",
      "Successfully built keras_facenet\n",
      "Installing collected packages: keras_facenet\n",
      "Successfully installed keras_facenet-0.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install keras_facenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3b8ce3c-3bd1-4c1e-ae50-c42c2382de1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from mtcnn import MTCNN\n",
    "\n",
    "#Initialize FaceNet and MTCNN\n",
    "facenet = FaceNet()\n",
    "facenet = load_model(\"facenet_keras.h5\")\n",
    "detector = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52338bb6-2446-4a46-9de6-cdab228b8a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base directory containing person subfolders\n",
    "base_dir = r\"C:\\Users\\USER\\Documents\\Semester 6\\Computer Vision\\facereg-facenet\\dataset\" # Replace with your actual path\n",
    "\n",
    "# Output dimensions required by FaceNet\n",
    "required_size = (160, 160)\n",
    "\n",
    "# Database to store all embeddings\n",
    "database = {\n",
    "    'names': [],\n",
    "    'embeddings': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ae4fee5-2bad-47ca-9321-3e0f4e8825b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 persons in the dataset folder.\n"
     ]
    }
   ],
   "source": [
    "# Get all person folders\n",
    "person_folders = [f for f in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, f))]\n",
    "\n",
    "print(f\"Found {len(person_folders)} persons in the dataset folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d22807e-ddb6-490d-809e-673de4888d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing people:   0%|                                                                         | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing people:  20%|█████████████                                                    | 1/5 [00:43<02:52, 43.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing people:  40%|██████████████████████████                                       | 2/5 [00:54<01:13, 24.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing people:  60%|███████████████████████████████████████                          | 3/5 [01:05<00:36, 18.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing people:  80%|████████████████████████████████████████████████████             | 4/5 [01:23<00:18, 18.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing people: 100%|█████████████████████████████████████████████████████████████████| 5/5 [01:35<00:00, 19.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database created with 45 face embeddings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process each person folder\n",
    "for person_name in tqdm(person_folders, desc=\"Processing people\"):\n",
    "    person_dir = os.path.join(base_dir, person_name)\n",
    "    image_files = [f for f in os.listdir(person_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    # Process each image for this person\n",
    "    for img_file in image_files:\n",
    "        img_path = os.path.join(person_dir, img_file)\n",
    "        \n",
    "        # Read the image\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            print(f\"Could not read image: {img_path}\")\n",
    "            continue\n",
    "            \n",
    "        # Convert to RGB (MTCNN expects RGB)\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Detect faces\n",
    "        faces = detector.detect_faces(image_rgb)\n",
    "        \n",
    "        if not faces:\n",
    "            print(f\"No face detected in: {img_path}\")\n",
    "            continue\n",
    "            \n",
    "        # Use the face with the highest confidence\n",
    "        face = max(faces, key=lambda x: x['confidence'])\n",
    "        if face['confidence'] < 0.95:\n",
    "            print(f\"Low confidence face detection in: {img_path}, skipping\")\n",
    "            continue\n",
    "            \n",
    "        # Extract face box coordinates\n",
    "        x, y, width, height = face['box']\n",
    "        \n",
    "        # Fix potential negative box coordinates from MTCNN\n",
    "        x, y = max(0, x), max(0, y)\n",
    "        \n",
    "        # Extract the face\n",
    "        face_image = image_rgb[y:y+height, x:x+width]\n",
    "        \n",
    "        # Resize to required dimensions\n",
    "        face_image = cv2.resize(face_image, required_size)\n",
    "        \n",
    "        # Get embedding\n",
    "        face_pixels = np.array(face_image)\n",
    "        embedding = facenet.embeddings([face_pixels])[0]\n",
    "        \n",
    "        # Add to database\n",
    "        database['names'].append(person_name)\n",
    "        database['embeddings'].append(embedding)\n",
    "\n",
    "# Convert lists to arrays for easier processing later\n",
    "database['embeddings'] = np.array(database['embeddings'])\n",
    "\n",
    "# Save the database\n",
    "with open('database.pkl', 'wb') as f:\n",
    "    pickle.dump(database, f)\n",
    "\n",
    "print(f\"Database created with {len(database['names'])} face embeddings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "066997ed-b236-4224-a63c-050638cd319a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Face count per person:\n",
      "               person  face_count\n",
      "0                amin          10\n",
      "1  sardor_abdirayimov          10\n",
      "2        jenna_ortega           9\n",
      "3       robert_downey           8\n",
      "4        taylor_swift           8\n"
     ]
    }
   ],
   "source": [
    "# Create a summary DataFrame for better visibility\n",
    "df = pd.DataFrame({\n",
    "    'person': database['names']\n",
    "})\n",
    "person_counts = df['person'].value_counts().reset_index()\n",
    "person_counts.columns = ['person', 'face_count']\n",
    "print(\"\\nFace count per person:\")\n",
    "print(person_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7e6ab0-65ef-46e0-98a6-6d228c369bf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "from mtcnn import MTCNN\n",
    "from keras_facenet import FaceNet\n",
    "import time\n",
    "\n",
    "# Configuration\n",
    "RECOGNITION_THRESHOLD = 0.8\n",
    "REQUIRED_SIZE = (160, 160)\n",
    "DETECTION_INTERVAL = 3  # Detect every N frames\n",
    "CONFIDENCE_THRESHOLD = 0.9\n",
    "\n",
    "def load_database(path='database.pkl'):\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            database = pickle.load(f)\n",
    "        print(f\"✅ Loaded face database with {len(database['names'])} entries.\")\n",
    "        return database\n",
    "    except FileNotFoundError:\n",
    "        print(\"❌ Error: 'database.pkl' not found. Please create the database first.\")\n",
    "        return None\n",
    "\n",
    "def preprocess_face(face, required_size=REQUIRED_SIZE):\n",
    "    try:\n",
    "        face = cv2.resize(face, required_size)\n",
    "        return np.asarray(face)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Face preprocessing failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def recognize_face(embedding, database):\n",
    "    distances = np.linalg.norm(database['embeddings'] - embedding, axis=1)\n",
    "    min_idx = np.argmin(distances)\n",
    "    min_distance = distances[min_idx]\n",
    "\n",
    "    if min_distance < RECOGNITION_THRESHOLD:\n",
    "        name = database['names'][min_idx]\n",
    "        confidence = 1.0 - (min_distance / RECOGNITION_THRESHOLD)\n",
    "        return name, confidence\n",
    "    else:\n",
    "        return \"Unknown\", 0.0\n",
    "\n",
    "def draw_face_box(frame, x, y, w, h, label, color):\n",
    "    cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "    cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "def main():\n",
    "    print(\"🔍 Initializing models...\")\n",
    "    database = load_database()\n",
    "    if database is None:\n",
    "        return\n",
    "\n",
    "    facenet = FaceNet()\n",
    "    detector = MTCNN()\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"❌ Error: Cannot access webcam.\")\n",
    "        return\n",
    "\n",
    "    print(\"🎥 Webcam ready. Press 'q' to quit.\")\n",
    "    frame_count = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"❌ Error: Failed to read frame.\")\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        display_frame = frame.copy()\n",
    "\n",
    "        if frame_count % DETECTION_INTERVAL == 0:\n",
    "            faces = detector.detect_faces(rgb_frame)\n",
    "            for face in faces:\n",
    "                if face['confidence'] < CONFIDENCE_THRESHOLD:\n",
    "                    continue\n",
    "\n",
    "                x, y, width, height = face['box']\n",
    "                x, y = max(0, x), max(0, y)\n",
    "                x2, y2 = x + width, y + height\n",
    "                x2, y2 = min(x2, frame.shape[1]), min(y2, frame.shape[0])\n",
    "\n",
    "                face_image = rgb_frame[y:y2, x:x2]\n",
    "                if face_image.size == 0:\n",
    "                    continue\n",
    "\n",
    "                processed_face = preprocess_face(face_image)\n",
    "                if processed_face is None:\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    embedding = facenet.embeddings([processed_face])[0]\n",
    "                    name, confidence = recognize_face(embedding, database)\n",
    "\n",
    "                    label = f\"{name} ({confidence*100:.1f}%)\" if name != \"Unknown\" else \"Unknown\"\n",
    "                    color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "\n",
    "                    draw_face_box(display_frame, x, y, width, height, label, color)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Error recognizing face: {e}\")\n",
    "                    continue\n",
    "\n",
    "        fps = frame_count / (time.time() - start_time)\n",
    "        cv2.putText(display_frame, f\"FPS: {fps:.2f}\", (10, 30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "\n",
    "        cv2.imshow(\"Face Recognition\", display_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"👋 Program terminated.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d37ee38-c8b8-4846-a872-5356dd3e5230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 2.2.5\n",
      "Uninstalling numpy-2.2.5:\n",
      "  Successfully uninstalled numpy-2.2.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\USER\\anaconda3\\envs\\tf_2.11\\Lib\\site-packages\\~umpy.libs'.\n",
      "You can safely remove it manually.\n",
      "WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\USER\\anaconda3\\envs\\tf_2.11\\Lib\\site-packages\\~umpy'.\n",
      "You can safely remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.18.5\n",
      "  Downloading numpy-1.18.5.zip (5.4 MB)\n",
      "     ---------------------------------------- 0.0/5.4 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/5.4 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.3/5.4 MB ? eta -:--:--\n",
      "     --- ------------------------------------ 0.5/5.4 MB 1.3 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 1.0/5.4 MB 1.4 MB/s eta 0:00:04\n",
      "     --------- ------------------------------ 1.3/5.4 MB 1.5 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 1.6/5.4 MB 1.6 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 1.6/5.4 MB 1.6 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 1.6/5.4 MB 1.6 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 1.6/5.4 MB 1.6 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 1.6/5.4 MB 1.6 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 1.8/5.4 MB 792.4 kB/s eta 0:00:05\n",
      "     ------------- -------------------------- 1.8/5.4 MB 792.4 kB/s eta 0:00:05\n",
      "     ------------- -------------------------- 1.8/5.4 MB 792.4 kB/s eta 0:00:05\n",
      "     ------------- -------------------------- 1.8/5.4 MB 792.4 kB/s eta 0:00:05\n",
      "     ------------- -------------------------- 1.8/5.4 MB 792.4 kB/s eta 0:00:05\n",
      "     --------------- ------------------------ 2.1/5.4 MB 618.1 kB/s eta 0:00:06\n",
      "     --------------- ------------------------ 2.1/5.4 MB 618.1 kB/s eta 0:00:06\n",
      "     --------------- ------------------------ 2.1/5.4 MB 618.1 kB/s eta 0:00:06\n",
      "     --------------- ------------------------ 2.1/5.4 MB 618.1 kB/s eta 0:00:06\n",
      "     --------------- ------------------------ 2.1/5.4 MB 618.1 kB/s eta 0:00:06\n",
      "     ----------------- ---------------------- 2.4/5.4 MB 526.3 kB/s eta 0:00:06\n",
      "     ----------------- ---------------------- 2.4/5.4 MB 526.3 kB/s eta 0:00:06\n",
      "     ----------------- ---------------------- 2.4/5.4 MB 526.3 kB/s eta 0:00:06\n",
      "     ----------------- ---------------------- 2.4/5.4 MB 526.3 kB/s eta 0:00:06\n",
      "     ----------------- ---------------------- 2.4/5.4 MB 526.3 kB/s eta 0:00:06\n",
      "     ------------------- -------------------- 2.6/5.4 MB 471.9 kB/s eta 0:00:06\n",
      "     ------------------- -------------------- 2.6/5.4 MB 471.9 kB/s eta 0:00:06\n",
      "     ------------------- -------------------- 2.6/5.4 MB 471.9 kB/s eta 0:00:06\n",
      "     ------------------- -------------------- 2.6/5.4 MB 471.9 kB/s eta 0:00:06\n",
      "     ------------------- -------------------- 2.6/5.4 MB 471.9 kB/s eta 0:00:06\n",
      "     --------------------- ------------------ 2.9/5.4 MB 435.7 kB/s eta 0:00:06\n",
      "     --------------------- ------------------ 2.9/5.4 MB 435.7 kB/s eta 0:00:06\n",
      "     --------------------- ------------------ 2.9/5.4 MB 435.7 kB/s eta 0:00:06\n",
      "     --------------------- ------------------ 2.9/5.4 MB 435.7 kB/s eta 0:00:06\n",
      "     --------------------- ------------------ 2.9/5.4 MB 435.7 kB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 3.1/5.4 MB 409.2 kB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 3.1/5.4 MB 409.2 kB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 3.1/5.4 MB 409.2 kB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 3.1/5.4 MB 409.2 kB/s eta 0:00:06\n",
      "     ------------------------- -------------- 3.4/5.4 MB 390.1 kB/s eta 0:00:06\n",
      "     ------------------------- -------------- 3.4/5.4 MB 390.1 kB/s eta 0:00:06\n",
      "     ------------------------- -------------- 3.4/5.4 MB 390.1 kB/s eta 0:00:06\n",
      "     ------------------------- -------------- 3.4/5.4 MB 390.1 kB/s eta 0:00:06\n",
      "     ------------------------- -------------- 3.4/5.4 MB 390.1 kB/s eta 0:00:06\n",
      "     -------------------------- ------------- 3.7/5.4 MB 376.0 kB/s eta 0:00:05\n",
      "     -------------------------- ------------- 3.7/5.4 MB 376.0 kB/s eta 0:00:05\n",
      "     -------------------------- ------------- 3.7/5.4 MB 376.0 kB/s eta 0:00:05\n",
      "     -------------------------- ------------- 3.7/5.4 MB 376.0 kB/s eta 0:00:05\n",
      "     -------------------------- ------------- 3.7/5.4 MB 376.0 kB/s eta 0:00:05\n",
      "     ---------------------------- ----------- 3.9/5.4 MB 365.8 kB/s eta 0:00:05\n",
      "     ---------------------------- ----------- 3.9/5.4 MB 365.8 kB/s eta 0:00:05\n",
      "     ---------------------------- ----------- 3.9/5.4 MB 365.8 kB/s eta 0:00:05\n",
      "     ---------------------------- ----------- 3.9/5.4 MB 365.8 kB/s eta 0:00:05\n",
      "     ---------------------------- ----------- 3.9/5.4 MB 365.8 kB/s eta 0:00:05\n",
      "     ---------------------------- ----------- 3.9/5.4 MB 365.8 kB/s eta 0:00:05\n",
      "     ---------------------------- ----------- 3.9/5.4 MB 365.8 kB/s eta 0:00:05\n",
      "     ---------------------------- ----------- 3.9/5.4 MB 365.8 kB/s eta 0:00:05\n",
      "     ---------------------------- ----------- 3.9/5.4 MB 365.8 kB/s eta 0:00:05\n",
      "     ---------------------------- ----------- 3.9/5.4 MB 365.8 kB/s eta 0:00:05\n",
      "     ------------------------------ --------- 4.2/5.4 MB 326.4 kB/s eta 0:00:04\n",
      "     ------------------------------ --------- 4.2/5.4 MB 326.4 kB/s eta 0:00:04\n",
      "     ------------------------------ --------- 4.2/5.4 MB 326.4 kB/s eta 0:00:04\n",
      "     ------------------------------ --------- 4.2/5.4 MB 326.4 kB/s eta 0:00:04\n",
      "     ------------------------------ --------- 4.2/5.4 MB 326.4 kB/s eta 0:00:04\n",
      "     ------------------------------ --------- 4.2/5.4 MB 326.4 kB/s eta 0:00:04\n",
      "     ------------------------------ --------- 4.2/5.4 MB 326.4 kB/s eta 0:00:04\n",
      "     ------------------------------ --------- 4.2/5.4 MB 326.4 kB/s eta 0:00:04\n",
      "     ------------------------------ --------- 4.2/5.4 MB 326.4 kB/s eta 0:00:04\n",
      "     -------------------------------- ------- 4.5/5.4 MB 299.6 kB/s eta 0:00:04\n",
      "     -------------------------------- ------- 4.5/5.4 MB 299.6 kB/s eta 0:00:04\n",
      "     -------------------------------- ------- 4.5/5.4 MB 299.6 kB/s eta 0:00:04\n",
      "     -------------------------------- ------- 4.5/5.4 MB 299.6 kB/s eta 0:00:04\n",
      "     -------------------------------- ------- 4.5/5.4 MB 299.6 kB/s eta 0:00:04\n",
      "     -------------------------------- ------- 4.5/5.4 MB 299.6 kB/s eta 0:00:04\n",
      "     -------------------------------- ------- 4.5/5.4 MB 299.6 kB/s eta 0:00:04\n",
      "     -------------------------------- ------- 4.5/5.4 MB 299.6 kB/s eta 0:00:04\n",
      "     -------------------------------- ------- 4.5/5.4 MB 299.6 kB/s eta 0:00:04\n",
      "     -------------------------------- ------- 4.5/5.4 MB 299.6 kB/s eta 0:00:04\n",
      "     ---------------------------------- ----- 4.7/5.4 MB 279.1 kB/s eta 0:00:03\n",
      "     ---------------------------------- ----- 4.7/5.4 MB 279.1 kB/s eta 0:00:03\n",
      "     ---------------------------------- ----- 4.7/5.4 MB 279.1 kB/s eta 0:00:03\n",
      "     ---------------------------------- ----- 4.7/5.4 MB 279.1 kB/s eta 0:00:03\n",
      "     ------------------------------------ --- 5.0/5.4 MB 277.8 kB/s eta 0:00:02\n",
      "     ------------------------------------ --- 5.0/5.4 MB 277.8 kB/s eta 0:00:02\n",
      "     ------------------------------------ --- 5.0/5.4 MB 277.8 kB/s eta 0:00:02\n",
      "     ------------------------------------ --- 5.0/5.4 MB 277.8 kB/s eta 0:00:02\n",
      "     ------------------------------------ --- 5.0/5.4 MB 277.8 kB/s eta 0:00:02\n",
      "     ------------------------------------ --- 5.0/5.4 MB 277.8 kB/s eta 0:00:02\n",
      "     -------------------------------------- - 5.2/5.4 MB 275.3 kB/s eta 0:00:01\n",
      "     ---------------------------------------- 5.4/5.4 MB 283.1 kB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [22 lines of output]\n",
      "  Running from numpy source directory.\n",
      "  <string>:461: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\USER\\anaconda3\\envs\\tf_2.11\\lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 389, in <module>\n",
      "      main()\n",
      "    File \"C:\\Users\\USER\\anaconda3\\envs\\tf_2.11\\lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 373, in main\n",
      "      json_out[\"return_val\"] = hook(**hook_input[\"kwargs\"])\n",
      "    File \"C:\\Users\\USER\\anaconda3\\envs\\tf_2.11\\lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 175, in prepare_metadata_for_build_wheel\n",
      "      return hook(metadata_directory, config_settings)\n",
      "    File \"C:\\Users\\USER\\AppData\\Local\\Temp\\pip-build-env-_sojtmeo\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 374, in prepare_metadata_for_build_wheel\n",
      "      self.run_setup()\n",
      "    File \"C:\\Users\\USER\\AppData\\Local\\Temp\\pip-build-env-_sojtmeo\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 512, in run_setup\n",
      "      super().run_setup(setup_script=setup_script)\n",
      "    File \"C:\\Users\\USER\\AppData\\Local\\Temp\\pip-build-env-_sojtmeo\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 317, in run_setup\n",
      "      exec(code, locals())\n",
      "    File \"<string>\", line 488, in <module>\n",
      "    File \"<string>\", line 465, in setup_package\n",
      "    File \"C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-44_y8y17\\numpy_063db0016454402b9064b6322641dfb0\\numpy\\distutils\\__init__.py\", line 26, in <module>\n",
      "      from . import ccompiler\n",
      "    File \"C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-44_y8y17\\numpy_063db0016454402b9064b6322641dfb0\\numpy\\distutils\\ccompiler.py\", line 111, in <module>\n",
      "      replace_method(CCompiler, 'find_executables', CCompiler_find_executables)\n",
      "  NameError: name 'CCompiler' is not defined. Did you mean: 'ccompiler'?\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall numpy -y\n",
    "!pip install numpy==1.18.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03a1962-744a-4e93-a0ca-dce7edf1be27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2df18d-7a1a-4ebb-9eff-54cb2de6df58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
